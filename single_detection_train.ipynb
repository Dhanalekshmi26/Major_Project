{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4246 images belonging to 20 classes.\n",
      "Found 628 images belonging to 20 classes.\n",
      "Epoch 1/20\n",
      "133/133 [==============================] - 212s 2s/step - loss: 1.8287 - accuracy: 0.4621 - val_loss: 0.9260 - val_accuracy: 0.7070 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "133/133 [==============================] - 194s 1s/step - loss: 1.1298 - accuracy: 0.6437 - val_loss: 0.6501 - val_accuracy: 0.8010 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "133/133 [==============================] - 185s 1s/step - loss: 0.9720 - accuracy: 0.7011 - val_loss: 0.5035 - val_accuracy: 0.8551 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "133/133 [==============================] - 187s 1s/step - loss: 0.9249 - accuracy: 0.7160 - val_loss: 0.5305 - val_accuracy: 0.8471 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "133/133 [==============================] - 180s 1s/step - loss: 0.8513 - accuracy: 0.7405 - val_loss: 0.4538 - val_accuracy: 0.8615 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "133/133 [==============================] - 174s 1s/step - loss: 0.8136 - accuracy: 0.7468 - val_loss: 0.4297 - val_accuracy: 0.8615 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "133/133 [==============================] - 172s 1s/step - loss: 0.7474 - accuracy: 0.7638 - val_loss: 0.4593 - val_accuracy: 0.8599 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "133/133 [==============================] - 172s 1s/step - loss: 0.7411 - accuracy: 0.7720 - val_loss: 0.4107 - val_accuracy: 0.8758 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "133/133 [==============================] - 2836s 21s/step - loss: 0.7026 - accuracy: 0.7786 - val_loss: 0.3674 - val_accuracy: 0.9029 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "133/133 [==============================] - 195s 1s/step - loss: 0.6796 - accuracy: 0.7894 - val_loss: 0.3692 - val_accuracy: 0.8997 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "133/133 [==============================] - 194s 1s/step - loss: 0.6634 - accuracy: 0.7958 - val_loss: 0.4060 - val_accuracy: 0.8790 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6577 - accuracy: 0.7913\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "133/133 [==============================] - 219s 2s/step - loss: 0.6577 - accuracy: 0.7913 - val_loss: 0.3763 - val_accuracy: 0.8997 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "133/133 [==============================] - 215s 2s/step - loss: 0.5669 - accuracy: 0.8255 - val_loss: 0.3359 - val_accuracy: 0.9061 - lr: 5.0000e-04\n",
      "Epoch 14/20\n",
      "133/133 [==============================] - 192s 1s/step - loss: 0.5372 - accuracy: 0.8311 - val_loss: 0.3425 - val_accuracy: 0.9029 - lr: 5.0000e-04\n",
      "Epoch 15/20\n",
      "133/133 [==============================] - 219s 2s/step - loss: 0.5253 - accuracy: 0.8375 - val_loss: 0.3109 - val_accuracy: 0.9140 - lr: 5.0000e-04\n",
      "Epoch 16/20\n",
      "133/133 [==============================] - 189s 1s/step - loss: 0.5076 - accuracy: 0.8396 - val_loss: 0.3492 - val_accuracy: 0.9029 - lr: 5.0000e-04\n",
      "Epoch 17/20\n",
      "133/133 [==============================] - 201s 2s/step - loss: 0.4964 - accuracy: 0.8512 - val_loss: 0.3180 - val_accuracy: 0.9076 - lr: 5.0000e-04\n",
      "Epoch 18/20\n",
      "133/133 [==============================] - 198s 1s/step - loss: 0.4942 - accuracy: 0.8382 - val_loss: 0.3047 - val_accuracy: 0.9029 - lr: 5.0000e-04\n",
      "Epoch 19/20\n",
      "133/133 [==============================] - 186s 1s/step - loss: 0.4773 - accuracy: 0.8528 - val_loss: 0.3221 - val_accuracy: 0.9013 - lr: 5.0000e-04\n",
      "Epoch 20/20\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.4737 - accuracy: 0.8509Restoring model weights from the end of the best epoch: 15.\n",
      "133/133 [==============================] - 184s 1s/step - loss: 0.4737 - accuracy: 0.8509 - val_loss: 0.3093 - val_accuracy: 0.9108 - lr: 5.0000e-04\n",
      "Epoch 20: early stopping\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 286s 2s/step - loss: 1.2417 - accuracy: 0.6333 - val_loss: 0.3135 - val_accuracy: 0.9124 - lr: 1.0000e-05\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 249s 2s/step - loss: 0.9138 - accuracy: 0.7247 - val_loss: 0.3177 - val_accuracy: 0.9140 - lr: 1.0000e-05\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 231s 2s/step - loss: 0.8005 - accuracy: 0.7598 - val_loss: 0.3183 - val_accuracy: 0.9092 - lr: 1.0000e-05\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 236s 2s/step - loss: 0.7351 - accuracy: 0.7758 - val_loss: 0.3065 - val_accuracy: 0.9156 - lr: 1.0000e-05\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 247s 2s/step - loss: 0.6935 - accuracy: 0.7885 - val_loss: 0.3079 - val_accuracy: 0.9204 - lr: 1.0000e-05\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 265s 2s/step - loss: 0.6475 - accuracy: 0.8036 - val_loss: 0.3089 - val_accuracy: 0.9124 - lr: 1.0000e-05\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6262 - accuracy: 0.8076\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "133/133 [==============================] - 244s 2s/step - loss: 0.6262 - accuracy: 0.8076 - val_loss: 0.3133 - val_accuracy: 0.9156 - lr: 1.0000e-05\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 250s 2s/step - loss: 0.6077 - accuracy: 0.8104 - val_loss: 0.3189 - val_accuracy: 0.9092 - lr: 5.0000e-06\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 244s 2s/step - loss: 0.5785 - accuracy: 0.8238 - val_loss: 0.3197 - val_accuracy: 0.9124 - lr: 5.0000e-06\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.5667 - accuracy: 0.8271\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "133/133 [==============================] - 239s 2s/step - loss: 0.5667 - accuracy: 0.8271 - val_loss: 0.3214 - val_accuracy: 0.9076 - lr: 5.0000e-06\n",
      "Epoch 10: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model Training Complete & Saved as 'ewaste_mobilenetv2.h5'! ðŸš€\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import os\n",
    "\n",
    "# âœ… Define Dataset Paths\n",
    "BASE_DIR = r\"C:\\Users\\lenovo\\OneDrive\\Desktop\\E-WASTE-ANALYSIS-AND-PREDICTING-RECYCLING-METHOD\"\n",
    "TRAIN_PATH = os.path.join(BASE_DIR, \"train\")\n",
    "VALID_PATH = os.path.join(BASE_DIR, \"valid\")\n",
    "TEST_PATH = os.path.join(BASE_DIR, \"test\")  # For testing after training\n",
    "\n",
    "# âœ… Image Properties\n",
    "IMG_SIZE = (224, 224)  # MobileNetV2 recommended size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# âœ… Stronger Data Augmentation to Improve Accuracy\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.6, 1.4],  \n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "# âœ… Load Dataset\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    TRAIN_PATH, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_data = valid_datagen.flow_from_directory(\n",
    "    VALID_PATH, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "# âœ… Load Pretrained MobileNetV2 Model\n",
    "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Initially freeze the base model\n",
    "\n",
    "# âœ… Custom Classification Head\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dropout(0.4)(x)  # Increased dropout for better generalization\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output_layer = Dense(len(train_data.class_indices), activation=\"softmax\")(x)  # Output layer\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "\n",
    "# âœ… Compile Model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# âœ… Callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\n",
    "early_stop = EarlyStopping(monitor=\"val_accuracy\", patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# âœ… Train Model\n",
    "EPOCHS = 20\n",
    "history = model.fit(train_data, validation_data=val_data, epochs=EPOCHS, callbacks=[reduce_lr, early_stop])\n",
    "\n",
    "# âœ… Fine-Tune Top Layers (for Higher Accuracy)\n",
    "base_model.trainable = True  # Unfreeze base model\n",
    "for layer in base_model.layers[:100]:  # Keep first 100 layers frozen\n",
    "    layer.trainable = False\n",
    "\n",
    "# âœ… Recompile with Lower LR\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# âœ… Train Again with Fine-Tuning\n",
    "fine_tune_epochs = 10\n",
    "history_finetune = model.fit(train_data, validation_data=val_data, epochs=fine_tune_epochs, callbacks=[reduce_lr, early_stop])\n",
    "\n",
    "# âœ… Save Model\n",
    "model.save(\"ewaste_mobilenetv2.h5\")\n",
    "\n",
    "print(\"âœ… Model Training Complete & Saved as 'ewaste_mobilenetv2.h5'! ðŸš€\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
